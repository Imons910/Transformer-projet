{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836ec1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41af539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è MODE CPU FORC√â (Lent mais stable pour g√©n√©rer le rapport)\n",
      "‚è≥ Chargement du mod√®le...\n",
      "trainable params: 294,912 || all params: 25,080,001 || trainable%: 1.1759\n",
      "üìÇ Donn√©es : c:\\Users\\simon\\Documents\\git\\Transformer-projet\\DATASET_DEVOIR\n",
      "üî• C'est parti pour 10 √©poques !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:21<00:00,  5.46s/it, Delta=0.110, Loss=1.6556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 1 termin√© | Loss: 2.0889 | Pr√©cision (Delta): 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:18<00:00,  5.20s/it, Delta=0.142, Loss=1.2178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 2 termin√© | Loss: 1.0025 | Pr√©cision (Delta): 0.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:17<00:00,  5.18s/it, Delta=0.183, Loss=0.8615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 3 termin√© | Loss: 0.6454 | Pr√©cision (Delta): 0.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:18<00:00,  5.26s/it, Delta=0.479, Loss=0.3158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 4 termin√© | Loss: 0.3881 | Pr√©cision (Delta): 0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:21<00:00,  5.44s/it, Delta=0.489, Loss=0.1750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 5 termin√© | Loss: 0.2432 | Pr√©cision (Delta): 0.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:17<00:00,  5.15s/it, Delta=0.724, Loss=0.1319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 6 termin√© | Loss: 0.1795 | Pr√©cision (Delta): 0.6078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:24<00:00,  5.63s/it, Delta=0.648, Loss=0.1218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 7 termin√© | Loss: 0.1377 | Pr√©cision (Delta): 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:25<00:00,  5.68s/it, Delta=0.629, Loss=0.1410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 8 termin√© | Loss: 0.1176 | Pr√©cision (Delta): 0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:30<00:00,  6.05s/it, Delta=0.878, Loss=0.0576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 9 termin√© | Loss: 0.0972 | Pr√©cision (Delta): 0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:34<00:00,  6.33s/it, Delta=0.821, Loss=0.1045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Epoch 10 termin√© | Loss: 0.0898 | Pr√©cision (Delta): 0.7977\n",
      "üéâ Termin√© ! Mod√®le sauvegard√© dans : ./resultats_projet\\modele_final_lora\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # Barre de progression\n",
    "\n",
    "# Hugging Face & LoRA\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (MODE S√âCURIT√â)\n",
    "# ==========================================\n",
    "# METS \"True\" POUR TON PC (Pour √©viter le crash RTX 5070 / Driver)\n",
    "# METS \"False\" QUAND TU LANCES SUR LE CLUSTER DE L'ECOLE\n",
    "FORCE_CPU = True\n",
    "\n",
    "MODEL_ID = \"depth-anything/Depth-Anything-V2-Small-hf\"\n",
    "OUTPUT_DIR = \"./resultats_projet\"\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 10  # Suffisant pour avoir des r√©sultats visibles\n",
    "\n",
    "# Choix du processeur\n",
    "if FORCE_CPU:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"‚ö†Ô∏è MODE CPU FORC√â (Lent mais stable pour g√©n√©rer le rapport)\")\n",
    "else:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"üöÄ D√©marrage sur : {DEVICE}\")\n",
    "    if DEVICE == \"cuda\":\n",
    "        print(f\"Carte : {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATASET (Zivid + Correction Unit√©s)\n",
    "# ==========================================\n",
    "class ZividDataset(Dataset):\n",
    "    def __init__(self, root_dir, processor):\n",
    "        self.img_dir = os.path.join(root_dir, \"images\")\n",
    "        self.depth_dir = os.path.join(root_dir, \"depth\")\n",
    "        self.processor = processor\n",
    "        \n",
    "        valid_ext = ('.png', '.jpg', '.jpeg')\n",
    "        if not os.path.exists(self.img_dir):\n",
    "             raise FileNotFoundError(f\"‚ùå Dossier introuvable : {self.img_dir}\")\n",
    "\n",
    "        self.images = sorted([f for f in os.listdir(self.img_dir) if f.lower().endswith(valid_ext)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        # On remplace _color.jpg par _rawDepth.npy\n",
    "        base_name = os.path.splitext(img_name)[0].replace(\"_color\", \"\")\n",
    "        npy_name = base_name + \"_rawDepth.npy\"\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        npy_path = os.path.join(self.depth_dir, npy_name)\n",
    "\n",
    "        # 1. Image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # 2. Profondeur (V√©rit√© Terrain)\n",
    "        try:\n",
    "            point_cloud = np.load(npy_path)\n",
    "            depth_Z = point_cloud[:, :, 2] # On garde Z\n",
    "            \n",
    "            # --- IMPORTANT : CONVERSION MM -> METRES ---\n",
    "            # Si max > 100, c'est du mm. On divise par 1000 pour aider le mod√®le.\n",
    "            if np.nanmax(depth_Z) > 100:\n",
    "                depth_Z = depth_Z / 1000.0\n",
    "            # -------------------------------------------\n",
    "            \n",
    "        except Exception:\n",
    "            return None # Skip si fichier illisible\n",
    "\n",
    "        # 3. Pr√©paration Inputs\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        target_h, target_w = inputs[\"pixel_values\"].shape[-2:]\n",
    "        \n",
    "        depth_tensor = torch.from_numpy(depth_Z).float().unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # 4. Masque (Ignorer les NaNs et valeurs <= 0)\n",
    "        mask = ~torch.isnan(depth_tensor) & ~torch.isinf(depth_tensor) & (depth_tensor > 0)\n",
    "        depth_tensor = torch.nan_to_num(depth_tensor, nan=0.0)\n",
    "        \n",
    "        # 5. Redimensionnement (Nearest pour ne pas inventer de donn√©es)\n",
    "        depth_resized = torch.nn.functional.interpolate(depth_tensor, size=(target_h, target_w), mode='nearest')\n",
    "        mask_resized = torch.nn.functional.interpolate(mask.float(), size=(target_h, target_w), mode='nearest')\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "            \"labels\": depth_resized.squeeze(0),\n",
    "            \"mask\": mask_resized.squeeze(0)\n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# 3. FONCTIONS M√âTRIQUES & VISUALISATION\n",
    "# ==========================================\n",
    "def compute_metrics(pred, target, mask):\n",
    "    \"\"\"Calcule AbsRel, RMSE et Delta < 1.25\"\"\"\n",
    "    pred = pred[mask]\n",
    "    target = target[mask]\n",
    "    \n",
    "    if len(target) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    # AbsRel (Erreur relative)\n",
    "    abs_rel = torch.mean(torch.abs(pred - target) / target)\n",
    "    # RMSE (Erreur quadratique)\n",
    "    rmse = torch.sqrt(torch.mean((pred - target) ** 2))\n",
    "    # Accuracy Delta < 1.25 (Combien de pixels sont pr√©cis ?)\n",
    "    max_ratio = torch.max(pred / target, target / pred)\n",
    "    delta1 = (max_ratio < 1.25).float().mean()\n",
    "\n",
    "    return abs_rel.item(), rmse.item(), delta1.item()\n",
    "\n",
    "def save_comparison_image(pixel_values, true_depth, pred_depth, epoch):\n",
    "    \"\"\"G√©n√®re l'image pour le rapport\"\"\"\n",
    "    # D√©normalisation image\n",
    "    img = pixel_values.permute(1, 2, 0).cpu().numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    \n",
    "    true_d = true_depth.squeeze().cpu().numpy()\n",
    "    pred_d = pred_depth.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(img); plt.title(\"Input RGB\"); plt.axis('off')\n",
    "    plt.subplot(1, 3, 2); plt.imshow(true_d, cmap='inferno'); plt.title(\"V√©rit√© (Z)\"); plt.axis('off')\n",
    "    plt.subplot(1, 3, 3); plt.imshow(pred_d, cmap='inferno'); plt.title(f\"Pr√©diction (Ep {epoch})\"); plt.axis('off')\n",
    "    \n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"resultat_epoch_{epoch}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 4. FONCTION MAIN (TRAIN)\n",
    "# ==========================================\n",
    "def run_project():\n",
    "    base_dir = os.getcwd()\n",
    "    dataset_dir = os.path.join(base_dir, \"DATASET_DEVOIR\")\n",
    "    \n",
    "    print(\"‚è≥ Chargement du mod√®le...\")\n",
    "    processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "    model = AutoModelForDepthEstimation.from_pretrained(MODEL_ID)\n",
    "    \n",
    "    # --- LoRA CONFIG ---\n",
    "    # On cible les modules d'attention\n",
    "    lora_config = LoraConfig(\n",
    "        r=16, lora_alpha=16, target_modules=[\"query\", \"value\"], \n",
    "        lora_dropout=0.1, bias=\"none\"\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.to(DEVICE)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    # --- DATASET ---\n",
    "    print(f\"üìÇ Donn√©es : {dataset_dir}\")\n",
    "    try:\n",
    "        dataset = ZividDataset(dataset_dir, processor)\n",
    "        dataset = [d for d in dataset if d is not None] # Filtre erreurs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur : {e}\"); return\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    print(f\"üî• C'est parti pour {EPOCHS} √©poques !\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        total_loss = 0\n",
    "        total_delta = 0\n",
    "        \n",
    "        loop = tqdm(loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(loop):\n",
    "            pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "            mask = batch[\"mask\"].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            predicted_depth = outputs.predicted_depth\n",
    "            \n",
    "            # Interpolation\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                predicted_depth.unsqueeze(1), size=labels.shape[-2:], \n",
    "                mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            \n",
    "            # Loss (Sur pixels valides seulement)\n",
    "            loss = torch.sum(mask * (prediction - labels)**2) / (torch.sum(mask) + 1e-6)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calcul M√©triques\n",
    "            with torch.no_grad():\n",
    "                abs_rel, rmse, d1 = compute_metrics(prediction, labels, mask.bool())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_delta += d1\n",
    "            \n",
    "            loop.set_postfix(Loss=f\"{loss.item():.4f}\", Delta=f\"{d1:.3f}\")\n",
    "\n",
    "            # Sauvegarde image t√©moin (1√®re batch seulement)\n",
    "            if batch_idx == 0:\n",
    "                save_comparison_image(pixel_values[0], labels[0], prediction[0], epoch)\n",
    "        \n",
    "        # Bilan Fin d'√âpoque\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        avg_delta = total_delta / len(loader)\n",
    "        print(f\"üèÅ Epoch {epoch} termin√© | Loss: {avg_loss:.4f} | Pr√©cision (Delta): {avg_delta:.4f}\")\n",
    "\n",
    "    # Sauvegarde finale\n",
    "    save_path = os.path.join(OUTPUT_DIR, \"modele_final_lora\")\n",
    "    model.save_pretrained(save_path)\n",
    "    print(f\"üéâ Termin√© ! Mod√®le sauvegard√© dans : {save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_project()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
